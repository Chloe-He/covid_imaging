# -*- coding: utf-8 -*-
"""BST 263 Final Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-JuQbWJJrX3L-_vFrRb7fdS5EW-yJ-Lh
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sn

from joblib import dump, load

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

from sklearn.svm import SVC, l1_min_c
from sklearn.linear_model import LogisticRegression
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.model_selection import GridSearchCV, RandomizedSearchCV
from sklearn import metrics

from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture
from sklearn.decomposition import PCA

"""**Load data**"""

# currently the coding is 
# run cleaning code
# url = 'https://raw.githubusercontent.com/boyercb/bst263-final-project/master/mydata_unique.csv'
url = 'https://raw.githubusercontent.com/boyercb/bst263-final-project/master/data/'
mydata = pd.read_csv(url + "mydata_all.csv")

X_train = pd.read_csv(url + "X_train.csv")
X_test = pd.read_csv(url + "X_test.csv")

y_train = pd.read_csv(url + "y_train.csv", header=None)
y_test = pd.read_csv(url + "y_test.csv", header=None)

y_train = y_train.iloc[:, 0]
y_test = y_test.iloc[:, 0]

"""**SKIP/COMMENT OUT THIS SECTION IF RUNNING AUGMENTED**"""

# create training and validation sets

# total column number
# cols = mydata.shape[1]
# col_image_end = cols-5
# col_label = cols-1

# train, test = train_test_split(mydata, test_size=0.20, random_state=42)

# X_train, y_train = train.iloc[:, 0:col_image_end], train.iloc[:, col_label]
# X_test, y_test = test.iloc[:, 0:col_image_end], test.iloc[:, col_label]

"""**Image pre-processing**"""

# preprocessing 
scaler = StandardScaler().fit(X_train)
X_std = scaler.fit_transform(X_train)
X_test_std = scaler.fit_transform(X_test)

# constants
n_folds = 10
seed = 3370

model_names = ["SVM linear", "Logistic", "Random Forest", "LDA", "QDA", "XGBoost", "Naive Bayes", "Ensemble"]
filenames = ["svm_rbf_aug", "logistic_aug", "rf_aug", "LDA_aug", "QDA_aug", "gb_aug", "bayes_aug", "ensemble_aug"]

# tuning parameters
svm_rbf_params = {
    'C': np.logspace(-4, 1, 25), 
    'gamma': np.logspace(-4, 0, 5)
}

svm_poly_params = {
    'C': np.logspace(-4, 1.5, 25), 
    'gamma': np.logspace(-4, 0, 5)
}

svm_sig_params = {
    'C': np.logspace(-4, 1, 25), 
    'gamma': np.logspace(-4, 0, 5)
}

svm_lin_params = {'C': np.logspace(-4, 0, 25)}

logit_params = {
    'C': np.logspace(-4, 0.5, 25), 
    'intercept_scaling': [100000],
    }

rf_params = {
    'bootstrap': [True],
    'max_depth': [int(x) for x in np.linspace(1, 100, 11)],
    'max_features': ['sqrt'],
    'min_samples_leaf': [3, 4],
    'min_samples_split': [8, 9, 10],
    'n_estimators': [int(x) for x in np.linspace(50, 1000, 5)]
}

gb_params = {
    'learning_rate': np.linspace(0.01, 0.1, num = 4),
    'max_depth': [1, 5, 10, 20, 40, 80, 100],
    'subsample': [0.8],
    'max_features': ['sqrt'],
    'min_samples_leaf': [3],
    'min_samples_split': [8],
    'n_estimators': [int(x) for x in np.linspace(10, 1000, 5)]
}

"""**Model 1: SVM**
1. Use "rbf" kernel
"""

# model: SVM - rbf
svc_rbf = SVC(kernel = "rbf", random_state=seed)
svm_rbf = GridSearchCV(
    svc_rbf, 
    svm_rbf_params, 
    cv=n_folds, 
    scoring='accuracy',
    verbose=2,
    n_jobs=-1
    )
svm_rbf.fit = svm_rbf.fit(X_std, y_train)

"""2. Use "poly" kernel"""

# model: SVM - poly kernel
svc_poly = SVC(kernel = "poly", random_state=seed)
svm_poly = GridSearchCV(
    svc_poly, 
    svm_poly_params, 
    cv=n_folds, 
    scoring='accuracy',
    verbose=2,
    n_jobs=-1
)
svm_poly.fit = svm_poly.fit(X_std, y_train)

"""3. Use "sigmoid" kernel"""

# model: SVM - sigmoid kernel
svc_sig = SVC(kernel = "sigmoid", random_state=seed)
svm_sig = GridSearchCV(
    svc_sig, 
    svm_sig_params, 
    cv=n_folds, 
    scoring='accuracy',
    verbose=2,
    n_jobs=-1
)
svm_sig.fit = svm_sig.fit(X_std, y_train)

"""4. Use "linear" kernel"""

# model: SVM - linear kernel
svc_lin = SVC(kernel = "linear", random_state=seed)
svm_lin = GridSearchCV(
    svc_lin, 
    svm_lin_params, 
    cv=n_folds, 
    scoring='accuracy', 
    verbose=2,
    n_jobs=-1)
svm_lin.fit = svm_lin.fit(X_std, y_train)

"""5. Compare prediction AUCs across different kernels"""

svm_models = [svm_rbf, svm_poly, svm_sig, svm_lin]
svm_names = ["SVM - rbf", "SVM - polynomial", "SVM - sigmoid", "SVM - linear"]

aucs_test = []
fig = plt.figure(figsize=(5,5))
ax = fig.add_subplot(1, 1, 1)
for mod in zip(svm_models, svm_names): 
    roc_output = metrics.plot_roc_curve(mod[0], X_test_std, y_test, 
                                        ax=ax, name=mod[1])
    aucs_test.append(roc_output.roc_auc)

ax.plot([0, 1], [0, 1], 'k--')
plt.show()

"""**Model 2: L1-logistic regression**"""

# model: L1-logistic regression
logit = LogisticRegression(penalty='l1', solver='liblinear', random_state=seed)
logistic = GridSearchCV(
    logit, 
    logit_params, 
    cv=n_folds, 
    scoring='accuracy',
    verbose=2,
    n_jobs=-1
    )

logistic.fit = logistic.fit(X_std, y_train)

# plot CV errors
b = logistic.cv_results_['mean_test_score'].argmax()

plt.figure().set_size_inches(8, 6)
plt.plot(logit_params['C'],1 - logistic.cv_results_['mean_test_score'])
plt.axvline(logit_params['C'][b], linestyle='--', color='red', label='Best log(C)')
plt.ylabel('Misclassification error')
plt.xlabel('ln(C)')
plt.title('CV error of logistic regression')
plt.legend(loc='lower right')
plt.show()

"""**Model 3: Random forest**"""

# model: Random forest 
rf = RandomForestClassifier(random_state=seed)
rf = GridSearchCV(  
    estimator=rf, 
    param_grid=rf_params, 
    cv=n_folds, 
    scoring='accuracy',
    verbose=2,  
    n_jobs=-1
)
rf.fit = rf.fit(X_std, y_train)

"""**Model 4: LDA**
1. Create PCs to reduce dimensions
"""

full_pca = PCA(random_state=0).fit(X_std)
full_pca.n_components_

cum_exp_var = np.cumsum(full_pca.explained_variance_ratio_) 

plt.plot(np.arange(len(cum_exp_var))+1, cum_exp_var)
plt.xlabel('Number of Components')
plt.ylabel('Proportion of Variance Explained');

cutoffs = np.flip(np.arange(0.5, 1, 0.05))
cutoffs_df = pd.DataFrame([[min(np.arange(len(cum_exp_var))[cum_exp_var > c]) + 1 for c in cutoffs]], 
                          columns=cutoffs, index=['Number of PCs Needed'])
cutoffs_df.columns.name = 'Variance Explained'
cutoffs_df

"""2. Fit LDA with PCs"""

# model: LDA
lda_pca = PCA(224, random_state=0).fit(X_std)
##lda_pca = PCA(153, random_state=0).fit(X_std)
X_std_lda = lda_pca.transform(X_std)
X_test_std_lda = lda_pca.transform(X_test_std)

LDA = LinearDiscriminantAnalysis()
LDA = LDA.fit(X_std_lda, y_train)

fig = plt.figure(figsize=(8,8))
ax = fig.add_subplot(1, 1, 1)
roc_output = metrics.plot_roc_curve(LDA, X_test_std_lda, y_test, ax=ax, name="LDA")

ax.plot([0, 1], [0, 1], 'k--')
plt.show()

"""**Model 5: QDA**
Fit model with PCs
"""

# model: QDA
qda_pca = PCA(330, random_state=0).fit(X_std)
##qda_pca = PCA(153, random_state=0).fit(X_std)
X_std_qda = qda_pca.transform(X_std)
X_test_std_qda = qda_pca.transform(X_test_std)

QDA = QuadraticDiscriminantAnalysis()
QDA=QDA.fit(X_std_lda, y_train)

fig = plt.figure(figsize=(8,8))
ax = fig.add_subplot(1, 1, 1)
roc_output = metrics.plot_roc_curve(QDA, X_test_std_lda, y_test, ax=ax, name="QDA")

ax.plot([0, 1], [0, 1], 'k--')
plt.show()

"""**Model 6: XGBoost**"""

# model: XGBoost
gb = GradientBoostingClassifier(random_state=seed) 
gb = GridSearchCV(
    estimator=gb, 
    param_grid=gb_params, 
    cv=n_folds, 
    scoring='accuracy',
    verbose=2, 
    n_jobs=-1
)
gb.fit = gb.fit(X_std, y_train)

"""**Model 7: Naive Bayes**"""

# model: Naive Bayes
bayes = GaussianNB()
bayes.fit(X_std, y_train)

"""**Model 8: Voting Ensemble Classifier**"""

# model: Ensemble
models = [
          ("Logistic",logistic.best_estimator_),
          ("Random Forest",rf.best_estimator_),
          ("XGBoost",gb.best_estimator_),
          ("Naive Bayes",bayes)]

ensemble = VotingClassifier(estimators=models, voting='soft')
ensemble.fit(X_std, y_train)

"""**Save trained models**"""

models = [svm_rbf, logistic, rf] #LDA, QDA, bayes] #gb, , ensemble]
filenames = ["svm_rbf_aug", "logistic_aug", "rf_aug"]

for mod in zip(models, filenames):
  dump(mod[0], mod[1])

"""**Load trained models (START HERE)**"""

svm_rbf = load('svm_rbf_aug')
#svm_lin = load('svm_lin_aug')
logistic = load('logistic_aug')
rf = load('rf_aug')
LDA = load('LDA_aug')
QDA = load('QDA_aug')
gb = load('gb_aug')
bayes = load('bayes_aug')
#ensemble = load('ensemble_aug')

# rwdir = "/Volumes/GoogleDrive/My Drive/Serious stuff/AY19:20 Course materials/BST263/Project/"
# svm_lin = load(rwdir + 'svm_rbf_aug')
# logistic = load(rwdir + 'logistic_aug')
# rf = load(rwdir + 'rf_aug')
# LDA = load(rwdir + 'LDA_aug')
# QDA = load(rwdir + 'QDA_aug')
# gb = load(rwdir + 'gb_aug')
# bayes = load(rwdir + 'bayes_aug')
# ensemble = load(rwdir + 'ensemble_aug')

"""**Model evaluation and comparison**"""

y_train_pred_svm_lin = svm_lin.fit.predict(X_std)
y_train_pred_logistic = logistic.fit.predict(X_std)
y_train_pred_rf = rf.fit.predict(X_std)
y_train_pred_lda = LDA.predict(X_std_lda)
y_train_pred_qda = QDA.predict(X_std_qda)
y_train_pred_xgb = gb.fit.predict(X_std)
y_train_pred_bayes = bayes.predict(X_std)
y_train_pred_ensemble = ensemble.predict(X_std)

models = [svm_rbf, logistic, rf, LDA, QDA, gb, bayes, ensemble]
model_names = ["SVM - RBF", "Logistic", "Random Forest", "LDA", "QDA", "XGBoost", "Naive Bayes", "Ensemble"]

aucs_train = []
fig = plt.figure(figsize=(8,8))
ax = fig.add_subplot(1, 1, 1)
for mod in zip(models, model_names): 
    if mod[1] == "LDA":
      roc_output = metrics.plot_roc_curve(mod[0], X_std_lda, y_train, 
                                        ax=ax, name=mod[1])
    elif mod[1] == "QDA":
      roc_output = metrics.plot_roc_curve(mod[0], X_std_qda, y_train, 
                                        ax=ax, name=mod[1])
    else:
      roc_output = metrics.plot_roc_curve(mod[0], X_std, y_train, 
                                        ax=ax, name=mod[1])
    aucs_train.append(roc_output.roc_auc)

ax.plot([0, 1], [0, 1], 'k--')
plt.show()

y_test_pred_svm_lin = svm_lin.fit.predict(X_test_std)
y_test_pred_logistic = logistic.fit.predict(X_test_std)
y_test_pred_rf = rf.fit.predict(X_test_std)
y_test_pred_lda = LDA.predict(X_test_std_lda)
y_test_pred_qda = QDA.predict(X_test_std_qda)
y_test_pred_xgb = gb.fit.predict(X_test_std)
y_test_pred_bayes = bayes.predict(X_test_std)
y_test_pred_ensemble = ensemble.predict(X_test_std)

aucs_test = []
fig = plt.figure(figsize=(10,10))
ax = fig.add_subplot(1, 1, 1)
for mod in zip(models, model_names): 
    if mod[1] == "LDA":
      roc_output = metrics.plot_roc_curve(mod[0], X_test_std_lda, y_test, 
                                        ax=ax, name=mod[1])
    elif mod[1] == "QDA":
      roc_output = metrics.plot_roc_curve(mod[0], X_test_std_qda, y_test, 
                                        ax=ax, name=mod[1])
    else:
      roc_output = metrics.plot_roc_curve(mod[0], X_test_std, y_test, 
                                        ax=ax, name=mod[1])
    aucs_test.append(roc_output.roc_auc)

ax.plot([0, 1], [0, 1], 'k--')
plt.show()
fig.savefig('roc_unaug.png')

y_pred_proba_logit = logistic.predict_proba(X_test_std)[:, 1]
fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_proba_logit)
roc = pd.DataFrame(np.column_stack([tpr, 1-fpr, thresholds]), columns=['Sensitivity', 'Specificity', 'Cutoffs'])
roc.to_csv("SESP.csv")

pd.DataFrame(np.vstack([aucs_train, aucs_test]), 
             index=["Training AUC", "Test AUC"], 
             columns=model_names)

"""**Visualization: Confusion matrices**"""

data = {'y_obs': y_test,
        'y_svm_lin': y_test_pred_svm_lin,
        'y_logistic': y_test_pred_logistic,
        'y_rf': y_test_pred_rf,
        'y_lda': y_test_pred_lda,
        'y_qda': y_test_pred_qda,
        'y_xgb': y_test_pred_xgb,
        'y_bayes': y_test_pred_bayes,
        'y_ensemble': y_test_pred_ensemble,
        }

df = pd.DataFrame(data)
colnames = ['y_svm_lin', 'y_logistic', 'y_rf', 'y_lda', 'y_qda', 'y_xgb', 'y_bayes', 'y_ensemble']
sn.set(font_scale=1.3)
for col in zip(colnames, model_names): 
  fig = plt.figure(figsize=(6.4, 5.6))
  name = 'Predicted (' + col[1] + ')'
  confusion_matrix = pd.crosstab(df['y_obs'], df[col[0]], rownames = ['Observed'], colnames = [name])
  sn.heatmap(confusion_matrix, fmt='.0f', cmap = "Reds", annot=True)
  plt.show()
  fig.savefig(col[1] + "_aug")

"""**Clustering/Data reduction**"""

# Generate PCAR
from sklearn.decomposition import PCA
full_pca = PCA(random_state=0).fit(X_std)
full_pca.n_components_

cum_exp_var = np.cumsum(full_pca.explained_variance_ratio_)

plt.plot(np.arange(len(cum_exp_var))+1, cum_exp_var)
plt.xlabel('Number of Components')
plt.ylabel('Proportion of Variance Explained');

cutoffs = np.flip(np.arange(0.5, 1, 0.05))
cutoffs_df = pd.DataFrame([[min(np.arange(len(cum_exp_var))[cum_exp_var > c]) + 1 for c in cutoffs]], 
                          columns=cutoffs, index=['Number of PCs Needed'])
cutoffs_df.columns.name = 'Variance Explained'
cutoffs_df

# model: KMeans
final_pca = PCA(165, random_state=0).fit(X_train)
pixels_transform = final_pca.transform(X_train)

kmeans_kpp = KMeans(n_clusters=2, init='k-means++', n_init=1, random_state=0).fit(pixels_transform)
kmeans_kpp_labels = kmeans_kpp.labels_

# model: EM
em_kmeans = GaussianMixture(n_components=2, init_params='kmeans', n_init=1, random_state=0).fit(pixels_transform)
em_kmeans_labels = em_kmeans.predict(pixels_transform)

svm_pca_rbf = GridSearchCV(
    svc_rbf, 
    svm_rbf_params, 
    cv=n_folds, 
    scoring='accuracy',
    verbose=2,
    n_jobs=-1
    )
svm_pca_rbf.fit = svm_rbf.fit(pixels_transform, y_train)

fig = plt.figure(figsize=(8,8))
ax = fig.add_subplot(1, 1, 1)
roc_output = metrics.plot_roc_curve(svm_rbf, final_pca.transform(X_test), y_test, 
                                        ax=ax, name="SVM + PCA")
ax.plot([0, 1], [0, 1], 'k--')
plt.show()

"""**Data Augmentation**"""

print(X_test.shape)
print(y_test.shape)
print(X_train.shape)
print(y_train.shape)